# -*- coding: utf-8 -*-
"""Housing Prices Neural Network.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1573uPzbDp-Jj9lHkWuD4zN5VnY5tGWPn
"""

#@title Imports
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from tqdm.notebook import tqdm
import os
import numpy as np
from torch.utils.data import Dataset, DataLoader
from skimage import io
import time
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.model_selection import train_test_split
import torchvision.transforms as transforms
from PIL import Image

#@title Mount Drive
from google.colab import drive
drive.mount("/content/drive")

cd '/content/drive/MyDrive/NETS 213 Final Project/resizedImages'

"""# Data Wrangling

"""

#Read the Data
df = pd.read_csv('/content/drive/MyDrive/NETS 213 Final Project/austinHousingData.csv')
df.head(3)

#Process the Data
def clean_data(df, encode, drop):
  df = df.dropna()
  df = df.drop(columns=drop)

  for column in encode:
    values = df[column].unique()

    def get_code(elt, vals):
      for id, val in enumerate(vals):
        if val == elt:
          return id
    
    df[column] = df[column].apply(lambda x: get_code(x, values))
  return df

encode = ['city', 'hasAssociation', 'hasCooling', 'hasGarage', 'hasHeating', 'hasSpa', 'hasView', 'homeType']
drop = ['streetAddress', 'zpid', 'description', 'latitude', 'longitude', 'latest_saledate', 'latest_salemonth', 'latest_saleyear', 'latestPriceSource', 'numOfPhotos']

df = clean_data(df, encode, drop)

df.shape
df.columns

# Create Training and Test DataSets
train, test = train_test_split(df, test_size=.01, random_state = 45)

train, test = train_test_split(df, test_size=.2, random_state = 45)

test.head(3)

"""# Data Loader

"""

class HousingDataset(Dataset):
  def __init__(self, data, image_transforms=None, data_transforms = None):
    self.labels = data['latestPrice'].to_numpy()
    self.images = data['homeImage'].to_numpy()
    self.data = data.drop(columns=['latestPrice', 'homeImage']).to_numpy()
    self.image_path = '/content/drive/MyDrive/NETS 213 Final Project/homeImages'
    self.image_transforms = image_transforms
    self.data_transforms = data_transforms

  def __getitem__(self, index):
    image = np.load(os.path.join(self.image_path, self.images[index] + '.npy'))
    features = torch.tensor(self.data[index])
    label = self.labels[index]

    if self.image_transforms:
      image = self.image_transforms(image)

    # if self.data_transforms:
    #   features = self.data_transforms(features)
    return image, features, label

  def __len__(self):
      return len(self.images)

# Define a transform that should be applied to data and
# instatiate train and test datasets and loaders
transform_images = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])
transform_data = transforms.Compose([transforms.ToTensor()])

#Instantiate a train set and test set from the dataframes
train_set = HousingDataset(data = train, image_transforms= transform_images, data_transforms=transform_data)
test_set = HousingDataset(data = test, image_transforms= transform_images, data_transforms=transform_data)

#Create dataloaders
train_loader = torch.utils.data.DataLoader(train_set, batch_size=16, shuffle=True)
test_loader = torch.utils.data.DataLoader(test_set, batch_size=16, shuffle=True)

class DataNet(nn.Module):
  def __init__(self):
    super(DataNet, self).__init__()
    self.linear_1 = nn.Linear(35 + 16, 64)
    self.linear_2 = nn.Linear(64, 128)
    self.linear_4 = nn.Linear(128, 128)
    self.linear_5 = nn.Linear(128, 1)

    self.batch_norm1 = nn.BatchNorm1d(128)
    self.batch_norm2 = nn.BatchNorm1d(256)

    self.dropout1 = nn.Dropout(p = 0.25)
    self.dropout2 = nn.Dropout(p = 0.5)

  def forward(self, x):
    x = F.relu(self.linear_1(x))
    x = F.relu(self.linear_2(x))
    x = self.dropout1(x)
    # x = F.relu(self.linear_3(x))
    x = F.relu(self.linear_4(x))
    # x = self.dropout2(x)
    x = self.linear_5(x)
    return x

class ImageNet(nn.Module):
  def __init__(self):
    super(ImageNet, self).__init__()
    self.conv1 = nn.Conv2d(3, 16, kernel_size = 3, padding=1)
    self.conv2 = nn.Conv2d(16, 32, kernel_size = 3, padding=1)
    self.conv3 = nn.Conv2d(32, 64, kernel_size = 2, padding=1)
    self.conv4 = nn.Conv2d(64, 32, kernel_size = 2, padding=1)
    self.conv5 = nn.Conv2d(32, 1, kernel_size = 2, padding=1)

    self.pool1 = nn.MaxPool2d(3)
    self.pool2 = nn.MaxPool2d(2)

    self.linear1 = nn.Linear(1936, 128)
    self.linear2 = nn.Linear(128, 64)
    self.linear3 = nn.Linear(64, 16)

    self.dropout = nn.Dropout(p = 0.35)

  def forward(self, x):
    #Convolution
    x = F.relu(self.conv1(x))
    x = F.relu(self.conv2(x))
    x = self.pool1(x)
    x = F.relu(self.conv3(x))
    x = F.relu(self.conv4(x))
    x = self.pool2(x)
    x = F.relu(self.conv5(x))

    x = torch.flatten(x, 1)
    x = F.relu(self.linear1(x))
    x = F.relu(self.linear2(x))
    x = self.dropout(x)
    x = torch.sigmoid(self.linear3(x))
    return x

class BigNet(nn.Module):
  def __init__(self):
    super(BigNet, self).__init__()
    self.image_net = ImageNet()
    self.data_net = DataNet()

  def forward(self, image, data):
    x = self.image_net(image)
    x = torch.cat((x, data), dim=-1)
    return self.data_net(x)

def train_test(net, criterion, optimizer, 
               train_data_loader, test_data_loader, device,
               num_epochs=5, verbose=True, training_plot=True):
  # train
  net.train()
  training_losses = []
  test_accuracy = []
  for epoch in tqdm(range(num_epochs)):
    running_loss = 0.0
    iters = 0
    for i, data in enumerate(train_data_loader):
      images, features, labels, = data
      features = features.to(device).float()
      labels = labels.to(device).float()
      images = images.to(device).float()
      optimizer.zero_grad()

      pred = net(images, features).squeeze()
      loss = criterion(pred, labels)
      loss.backward()
      optimizer.step()

      if verbose:
        running_loss += (loss.item() / 10000)
        iters += 1
        if i % 1000 == 0: #update for every 100 minbatches
          # break
    training_losses.append(running_loss /iters)
    net.eval()
    test_accuracy.append(test_model(net, test_data_loader))

    if epoch % 5 == 0:
      print('Epoch: ', epoch)
      print("Loss {}".format(training_losses[-1]))
      print("Average % Err {}".format(test_accuracy[-1]))
      print()
  

  if training_plot:
    fig, ax = plt.subplots(1, 2)
    ax[0].plot(training_losses)
    ax[1].plot(test_accuracy)
    ax[0].set_xlabel('Epoch')
    ax[0].set_ylabel('Training loss')
    ax[1].set_xlabel('Epoch')
    ax[1].set_ylabel('Average Deviation From Truth')
    plt.show()

device = "cuda"
# net = UNet(device).to(device)
net = BigNet().to(device)
criterion = nn.MSELoss()
optimizer = optim.Adam(net.parameters(), lr=0.01)
train_test(net, criterion, optimizer, train_loader, test_loader, device, num_epochs=10)

# features, label = next(iter(test_loader))
# pred = net(features.to(device).float())
# for i, j in zip(pred.cpu().squeeze(), label):
#   print(i.item(), j.item(), (i.item() - j.item()) / j.item())

def test_model(net, loader):
  average_err = 0
  iters = 0
  for i, data in enumerate(loader):
    images, features, labels, = data
    features = features.to(device).float()
    labels = labels.to(device).float()
    images = images.to(device).float()

    with torch.no_grad():
      pred = net(images, features)
      average_err += torch.sum(torch.abs(pred - labels) / labels)
      iters += pred.shape[0]
  return average_err / iters

# test(net, test_loader)

test_model(net, test_loader)