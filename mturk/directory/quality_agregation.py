# -*- coding: utf-8 -*-
"""Copy of Quality Agregation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HBbYD6mPfDmZyoPmULe5Zn9-Go3WJdx3
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.pyplot import figure
from collections import Counter, defaultdict

"""# Quality Control"""

#Remove any worker's vote if it is more than one standard deviation outside of the mean
def remove_bad_workers(df):
  means = defaultdict(float)
  std = defaultdict(float)
  group =  df.groupby(by=['zpid']).std()
  for i, std_i in zip(group.index, group['Answer.answerPrice']):
    std[i] = std_i
  
  group =  df.groupby(by=['zpid']).mean()
  for i, mean_i in zip(group.index, group['Answer.answerPrice']):
    means[i] = mean_i
  
  new_df = pd.DataFrame(columns= df.columns)
  for _, row in df.iterrows():
    zpid = row['zpid']
    if row['Answer.answerPrice'] > means[zpid] + std[zpid] or row['Answer.answerPrice'] < means[zpid] - std[zpid]:
      continue    
    new_df = new_df.append(row)
  new_df.to_csv('QC1_output.csv')
  return new_df

def mean(df):
  sum = defaultdict(float)
  count = defaultdict(int)
  out_dict = defaultdict(float)
  for _, row in df.iterrows():
    sum[row['zpid']] += row['Answer.answerPrice']
    count[row['zpid']] += 1
  
  for key in sum:
    out_dict[key] = sum[key]/ count[key]
  return out_dict

#Assign weights to workers based on thier reciprical average distance to the mean crowd price
def weigh_workers(df):
  within_mean = defaultdict(int)
  votes = defaultdict(int)
  means = defaultdict(float)
  group =  df.groupby(by=['zpid']).mean()
  for i, mean_i in zip(group.index, group['Answer.answerPrice']):
    means[i] = mean_i
  for _, row in df.iterrows():
    zpid = row['zpid']
    within_mean[row['WorkerId']] += abs(row['Answer.answerPrice'] - means[zpid]) / means[zpid]
    votes[row['WorkerId']] += 1
  
  quality = defaultdict(float)
  csv = []
  for id in votes:
    quality[id] = 1 / (within_mean[id] / votes[id])
    csv.append((id, quality[id]))
  df_csv = pd.DataFrame(csv, columns=['WorkerId', 'quality'])
  df_csv.to_csv('QC2_output.csv')
  return quality

"""# Aggregation"""

#Find the true label of each house as voted by workers (true label is mean guess)
def find_crowd_price(df):
  mean_price = defaultdict(float)
  votes = defaultdict(int)

  for _, row in df.iterrows():
    mean_price[row['zpid']] += float(row['Answer.answerPrice'])
    votes[row['zpid']] += 1

  for zpid in mean_price:
    mean_price[zpid] = mean_price[zpid] / votes[zpid]
  
  csv = []
  for id in mean_price:
    csv.append((id, mean_price[id]))
  out = pd.DataFrame(csv, columns=['zpid', 'crowd_price'])
  out.to_csv('AG1_output.csv')
  return out

#Find the true label of each house based on weight of workers (as weighted average)
#Find the true label of each house based on weight of workers (as weighted average)
def get_weighted_prices(df, quality):
  price = defaultdict(float)
  weight = defaultdict(float)

  for _, row in df.iterrows():
    zpid, worker_id = row['zpid'], row['WorkerId']
    price[zpid] += quality[worker_id] * row['Answer.answerPrice']
    weight[zpid] += quality[worker_id]
  
  final_prices = []
  for zpid in price:
    final_prices.append((zpid, price[zpid]/ (weight[zpid] + 0.001)))
  weighted_df = pd.DataFrame(final_prices, columns=['zpid', 'crowd_price'])
  weighted_df.to_csv('AG2_output.csv')
  return weighted_df

#Main

df_input = pd.read_csv('/content/batch_results.csv')

#Quality control 
QC1 = remove_bad_workers(df_input)
QC2 = weigh_workers(df_input)

AG1 = find_crowd_price(QC1)
AG2 = get_weighted_prices(df_input, QC2)
#remove_bad rows -> QC1 -> mean aggregation -> AG1
#weight workers -> QC2 (worker_id, quality) -> weighted average aggreagtion -> AG2

#For testing
QC2 = weigh_workers(df_input)

AG1 = find_crowd_price(QC1)
AG2 = get_weighted_prices(df_input, QC2)

def create_zipid_price_dict(df, zip_col, price_col):
  zip_prices = defaultdict(float)
  for _, row in df.iterrows():
    zip_prices[row[zip_col]] = row[price_col]
  return zip_prices

true_dict = create_zipid_price_dict(df_input, 'zpid', 'Input.latestPrice')
non_weighted_dict = create_zipid_price_dict(AG1, 'zpid', 'crowd_price')
weighted_dict = create_zipid_price_dict(AG2, 'zpid', 'crowd_price')
no_control_dict = mean(df_input)

def calculate_avg_err(guess_df, true_df):
  avg_sum, avg_count = 0, 0
  for key in true_df:
    guess, true = guess_df[key], true_df[key]
    avg_sum += (abs(guess - true) / true)
    avg_count += 1
  return avg_sum / avg_count

qc1_error = calculate_avg_err(non_weighted_dict, true_dict)
qc2_error = calculate_avg_err(weighted_dict, true_dict)
no_qc_error = calculate_avg_err(no_control_dict, true_dict)

#print("None Weighted Error (remove workers ooutside of 1 SDEV): ", qc1_error)
#print("Weighted Error: ", qc2_error)
#print("No Quality Control: ", no_qc_error)
plt.figure(figsize=(13,8))
#x-coords of left sides of bars
#1: no control
#2: unweighted qc1
#3: weighted qc2
#4: neural net no image
#5 neural net with image

left = [1, 2, 3, 4, 5]

#heights of the bars
height = [no_qc_error * 100, qc1_error * 100, qc2_error *100, 18.84, 15.63]

labels = ['No quality control', 'Removal of bad workers', 'Weighted workers', 
          'Neural net (no images)', 'Neural net (with images)']
plt.rcParams['font.size'] = '10'
plt.bar(left, height, tick_label = labels, width = 0.5, color = ['blue', 'grey'])
plt.xlabel('Method', fontsize = 12)
plt.ylabel('Percent average error', fontsize = 12)
plt.title('Percent Average Error of MTurk vs Neural Network Methods',
          fontsize = 16)

for index, value in enumerate(left):
    plt.text(value - 0.1, height[index]+1,
             str(round(height[index], 2)))
  
plt.show